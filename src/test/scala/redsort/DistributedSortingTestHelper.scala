// This file was generated by Google Gemini 3 Pro, with some manual rewrites.

package redsort

import cats._
import cats.effect._
import java.nio.file._
import java.nio.file.attribute.BasicFileAttributes
import scala.sys.process._
import scala.jdk.CollectionConverters._
import java.io.IOException
import java.io.File
import redsort.Logging.fileLogger
import redsort.master.{Args => MasterArgs}
import redsort.worker.{Configuration => WorkerArgs}
import redsort.worker.CmdParser.workingDir
import redsort.jobs.Common.NetAddr
import fs2.io.file.{Path => Fs2Path}
import redsort.jobs.Common.Mid
import redsort.jobs.Common.Wid
import java.util.concurrent.atomic.AtomicInteger

final case class TestConfig(
    name: String,
    numMachines: Int,
    numInputDirs: Int,
    numFilesPerInputDir: Int,
    recordsPerFile: Int,
    masterPort: Int,
    numWorkerThreads: Int,
    workerBasePort: Int,
    baseDir: Path,
    outFileSize: Long
) {
  def masterArgs: MasterArgs =
    new MasterArgs(
      numMachines = numMachines,
      port = masterPort,
      threads = numWorkerThreads,
      outFileSize = outFileSize
    )

  def workerArgs(mid: Int): WorkerArgs = {
    val workerDir = Fs2Path.fromNioPath(baseDir.resolve(s"worker$mid"))
    new WorkerArgs(
      masterAddress = new NetAddr("127.0.0.1", masterPort),
      inputDirs = (0 until numInputDirs).map(i => workerDir / s"input$i"),
      outputDir = workerDir / "output",
      workingDir = None,
      threads = numWorkerThreads,
      port = workerBasePort + 10 * mid,
      replicatorLocalPort = workerBasePort + 1000 + 10 * mid
    )
  }
}

class NextPort(initialPort: Int) {
  private var currentPort: AtomicInteger = new AtomicInteger(initialPort)
  def getNext: Int = currentPort.addAndGet(100)
}

object DistributedSortingTestHelper {

  /** Scaffolds a test environment for distributed sorting, generates data, runs the test body, and
    * validates the results using valsort.
    *
    * @param name
    *   The name of the test case (used for directory naming).
    * @param body
    *   A function that takes the base path string and returns the sequence of worker indices
    *   ordered by the key range they contain (Ascending).
    */
  def testSorting(
      name: String,
      numMachines: Int,
      numInputDirs: Int,
      numFilesPerInputDir: Int,
      recordsPerFile: Int,
      numWorkerThreads: Int,
      masterPort: Int,
      workerBasePort: Int,
      outFileSize: Long = 128 // 128MB
  )(body: TestConfig => IO[Seq[Int]]): IO[Unit] =
    fileLogger(name).use { logger =>
      for {
        // create test config
        baseDir <- IO(Paths.get("target", "test-sorting", name).toAbsolutePath)
        config = new TestConfig(
          name = name,
          numMachines = numMachines,
          numInputDirs = numInputDirs,
          numFilesPerInputDir = numFilesPerInputDir,
          recordsPerFile = recordsPerFile,
          masterPort = masterPort,
          numWorkerThreads = numWorkerThreads,
          workerBasePort = workerBasePort,
          baseDir = baseDir,
          outFileSize = outFileSize
        )

        // prepare, run, then validate.
        _ <- IO(prepare(config))
        machineOrder <- body(config)
        _ <- IO(validate(config.baseDir, machineOrder))
      } yield ()
    }

  private def prepare(config: TestConfig) = {
    // 0. Clean up previous run if exists
    if (Files.exists(config.baseDir)) {
      deleteRecursively(config.baseDir)
    }

    // 1. Scaffold directory structure
    val workers = (0 until config.numMachines).toSeq
    val inputDirs = (0 until config.numInputDirs).map(i => s"input$i")

    workers.foreach { w =>
      val workerPath = config.baseDir.resolve(s"worker$w")
      inputDirs.foreach { i =>
        Files.createDirectories(workerPath.resolve(i))
      }
    }
    Files.createDirectories(config.baseDir.resolve("master"))

    // 2. Run gensort
    // We maintain a running offset to ensure data is unique/contiguous across the whole set.
    var currentOffset = 0

    for {
      w <- workers
      i <- inputDirs
      fileIdx <- 0 until config.numFilesPerInputDir
    } {
      val outFile = config.baseDir.resolve(s"worker$w").resolve(i).resolve(s"input.$fileIdx")

      // gensort -b<offset> <count> <output_file>
      // -b specifies the starting record index to ensure correct global sorting potential
      val cmd =
        Seq("gensort", s"-b$currentOffset", config.recordsPerFile.toString, outFile.toString)

      val exitCode = cmd.!
      if (exitCode != 0) {
        throw new RuntimeException(s"gensort failed for $outFile with exit code $exitCode")
      }

      currentOffset += config.recordsPerFile
    }
  }

  private def validate(baseDir: Path, machineOrder: Seq[Int]) = {
    // 4. Run valsort
    // We must gather output files in the order of machines returned by the body.
    // Within a machine, we assume partition files are ordered by their partition number.

    val allOutputFiles = machineOrder.flatMap { workerIdx =>
      val outputDir = baseDir.resolve(s"worker$workerIdx").resolve("output")

      if (!Files.exists(outputDir)) {
        throw new RuntimeException(s"Output directory missing for worker$workerIdx: $outputDir")
      }

      // Get files, filter for "partition.<n>", sort them by order of <n>.
      val files = Files
        .list(outputDir)
        .iterator()
        .asScala
        .toSeq
        .filter(p => p.getFileName.toString.startsWith("partition."))
        .sortBy { p =>
          val fileName = p.getFileName.toString
          val index = fileName.substring("partition.".length, fileName.length).toInt
          index
        }

      if (files.isEmpty) {
        throw new RuntimeException(s"No partition files found in $outputDir")
      }

      files
    }

    if (allOutputFiles.isEmpty) {
      throw new RuntimeException("No output files found across any workers.")
    }

    // validate sort order
    // first create summary file for each partition files.
    val allSummaryFiles = allOutputFiles.map(p => {
      val fileName = p.getFileName.toString
      val index = fileName.substring("partition.".length, fileName.length).toInt
      val summaryFilePath = p.getParent().getParent().resolve(s"out$index.sum")
      val cmd = Seq("valsort", "-o", summaryFilePath.toString, p.toString)
      val exit = cmd.!

      if (exit != 0) {
        throw new RuntimeException(s"valsort summary generation failed for file ${p}.")
      }

      summaryFilePath
    })

    // then concatenate all summary files to all.sum file
    val catCmd = Seq("cat") ++ allSummaryFiles.map(_.toString)
    val summaryFile = baseDir.resolve("all.sum")
    val catExit = (catCmd #> new File(summaryFile.toString)).!
    if (catExit != 0) {
      throw new Error(s"failed to concatenate summary files to ${summaryFile.toString}")
    }

    // finally validate sort
    val valsortCmd = Seq("valsort", "-s", summaryFile.toString)
    val valsortExit = valsortCmd.!

    if (valsortExit != 0) {
      throw new RuntimeException(
        s"valsort validation failed. Checked ${allOutputFiles.size} files."
      )
    }

    // 5. Check for stray files
    machineOrder.foreach { workerIdx =>
      val outputDir = baseDir.resolve(s"worker$workerIdx").resolve("output")

      val files = Files.list(outputDir).iterator().asScala.toSeq
      files.foreach { path =>
        val fileName = path.getFileName.toString
        val isDirectory = Files.isDirectory(path)
        val isPartitionFile = fileName.startsWith("partition.") && !isDirectory

        if (!isPartitionFile) {
          throw new RuntimeException(s"Found unexpected entry in output directory: $path")
        }
      }
    }
  }

  private def deleteRecursively(path: Path): Unit = {
    Files.walkFileTree(
      path,
      new SimpleFileVisitor[Path] {
        override def visitFile(file: Path, attrs: BasicFileAttributes): FileVisitResult = {
          Files.delete(file)
          FileVisitResult.CONTINUE
        }
        override def postVisitDirectory(dir: Path, exc: IOException): FileVisitResult = {
          Files.delete(dir)
          FileVisitResult.CONTINUE
        }
      }
    )
  }

  def workerAddrsToMachineOrder(workerAddrs: Map[Wid, NetAddr]): Seq[Mid] =
    workerAddrs
      .filter { case (wid, _) => wid.wtid == 0 }
      .toList
      .sortBy { case (_, addr) => addr.port }
      .map { case (wid, _) => wid.mid }
}
